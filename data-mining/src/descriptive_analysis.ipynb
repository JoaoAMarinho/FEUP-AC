{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "from matplotlib import colors\n",
    "from clean import *\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.graph_objects as go\n",
    "from itertools import product\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ml_utils import draw_decision_tree\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../test_ml/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_tree(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(data):\n",
    "    n_components = len(data.columns)\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(data)\n",
    "    variance = pca.explained_variance_ratio_ \n",
    "    var=np.cumsum(np.round(variance, 3)*100)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.ylabel('% Variance Explained')\n",
    "    plt.xlabel('# of Features')\n",
    "    plt.title('PCA Analysis')\n",
    "    plt.ylim(0,100.5)\n",
    "    plt.plot(var)\n",
    "    plt.show()\n",
    "\n",
    "def dbscan_param_tuning_silhouette(df_scale):\n",
    "    eps_values = np.arange(0.2,1.5,0.1) \n",
    "    min_samples = np.arange(2,5) \n",
    "    dbscan_params = list(product(eps_values, min_samples))\n",
    "    no_of_clusters = []\n",
    "    sil_score = []\n",
    "    epsvalues = []\n",
    "    min_samp = []\n",
    "\n",
    "    for p in dbscan_params:\n",
    "        dbscan_cluster = DBSCAN(eps=p[0], min_samples=p[1]).fit(df_scale)\n",
    "        epsvalues.append(p[0])\n",
    "        min_samp.append(p[1])\n",
    "        if len(np.unique(dbscan_cluster.labels_)) > 1:\n",
    "            no_of_clusters.append(len(np.unique(dbscan_cluster.labels_)))\n",
    "            sil_score.append(silhouette_score(df_scale, dbscan_cluster.labels_))\n",
    "\n",
    "    eps_min = list(zip(no_of_clusters, sil_score, epsvalues, min_samp))\n",
    "    eps_min_df = pd.DataFrame(eps_min, columns=['no_of_clusters', 'silhouette_score', 'epsilon_values', 'minimum_points'])\n",
    "    print(eps_min_df)\n",
    "\n",
    "def pca(n_components, data):\n",
    "    pca_cols = []\n",
    "    for i in range(n_components):\n",
    "        pca_cols.append('pc'+str(i+1))\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(data)\n",
    "    pca_scale = pca.transform(data)\n",
    "    pca_df = pd.DataFrame(pca_scale, columns=pca_cols)\n",
    "\n",
    "    return pca_df\n",
    "\n",
    "def elbow_method(df):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    nr_clusters = []\n",
    "    inertias = []\n",
    "    range_values = np.arange(2,8)\n",
    "\n",
    "    for k in range_values:\n",
    "        kmeans = KMeans(k)\n",
    "        kmeans.fit(df_copy)\n",
    "        nr_clusters.append(k)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.plot(nr_clusters, inertias, \"-o\", color='#138f8d')\n",
    "    plt.title('Evolution of Inertia with number of clusters')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.show()\n",
    "\n",
    "def silhouette_score(df, labels):\n",
    "    return metrics.silhouette_score(df, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_kmeans(df, n_clusters=3, init_method='k-means++', n_components=2):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_copy)\n",
    "    X_scale = scaler.transform(df_copy)\n",
    "    df_copy = pd.DataFrame(X_scale, columns=df_copy.columns)\n",
    "\n",
    "    # Reduce dimensionality with PCA\n",
    "    if len(df_copy.columns) > 3:\n",
    "        # Analyse PCA\n",
    "        if DEBUG:\n",
    "            pca_analysis(df)\n",
    "        df_pca = pca(n_components, df)\n",
    "        if DEBUG:\n",
    "            elbow_method(df_pca)\n",
    "\n",
    "        # Compute K-Means\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init=init_method)\n",
    "        kmeans.fit_predict(df_pca)\n",
    "                \n",
    "        print(\"KMeans Clusters: \\n\", Counter(kmeans.labels_))\n",
    "        print(\"KMeans Centers: \\n\", kmeans.cluster_centers_)\n",
    "        print(f'KMeans Inertia: \\n{kmeans.inertia_}')\n",
    "        print(f'KMeans Silhouette Score: \\n{silhouette_score(df_pca, kmeans.labels_)}')\n",
    "\n",
    "        # Plot results\n",
    "        if n_components == 2:\n",
    "            Scene = dict(xaxis = dict(title  = 'PC1'),yaxis = dict(title  = 'PC2'))\n",
    "            trace = go.Scatter(x=df_pca.iloc[:,0], y=df_pca.iloc[:,1], mode='markers',marker=dict(color = kmeans.labels_, colorscale='bluered', size = 10, line = dict(width = 0)))\n",
    "        else: \n",
    "            Scene = dict(xaxis = dict(title  = 'PC1'),yaxis = dict(title  = 'PC2'), zaxis= dict(title  = 'PC3'))\n",
    "            trace = go.Scatter3d(x=df_pca.iloc[:,0], y=df_pca.iloc[:,1], z=df_pca.iloc[:,2], mode='markers',marker=dict(color = kmeans.labels_, colorscale='rainbow', size = 10, line = dict(width = 0)))\n",
    "        layout = go.Layout(scene = Scene, height = 1000,width = 1000)\n",
    "        data = [trace]\n",
    "        fig = go.Figure(data = data, layout = layout)\n",
    "        fig.update_layout(title=\"KMeans Clusters\",font=dict(size=16))\n",
    "        fig.show()\n",
    "\n",
    "        clusters_pca_scale = pd.concat([df_pca, pd.DataFrame({'cluster':kmeans.labels_})], axis=1)\n",
    "        cluster_pca_profile = pd.merge(df_copy, clusters_pca_scale['cluster'], left_index=True, right_index=True)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(cluster_pca_profile.groupby('cluster').mean())\n",
    "            print(cluster_pca_profile.groupby('cluster').min())\n",
    "            print(cluster_pca_profile.groupby('cluster').max())\n",
    "            print(cluster_pca_profile.groupby('cluster').std())\n",
    "            \n",
    "    else:\n",
    "        if DEBUG:\n",
    "            elbow_method(df_copy)\n",
    "\n",
    "        # Compute K-Means\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init=init_method)\n",
    "        kmeans.fit_predict(df_copy)\n",
    "\n",
    "        print(\"KMeans Clusters: \\n\", Counter(kmeans.labels_))\n",
    "        print(\"KMeans Centers: \\n\", kmeans.cluster_centers_)\n",
    "        print(f'KMeans Inertia: \\n{kmeans.inertia_}')\n",
    "        print(f'KMeans Silhouette Score: \\n{silhouette_score(df_copy, kmeans.labels_)}')\n",
    "        print()\n",
    "\n",
    "        # Plot results\n",
    "        if len(df_copy.columns) == 2:\n",
    "            Scene = dict(xaxis = dict(title = df_copy.columns[0]),yaxis = dict(title  = df_copy.columns[1]))\n",
    "            trace = go.Scatter(x=df_copy.iloc[:,0], y=df_copy.iloc[:,1], mode='markers',marker=dict(color=kmeans.labels_, colorscale='rainbow', size = 7, line = dict(width = 0)))\n",
    "        else: \n",
    "            Scene = dict(xaxis = dict(title = df_copy.columns[0]),yaxis = dict(title = df_copy.columns[1]), zaxis= dict(title = df_copy.columns[2]))\n",
    "            trace = go.Scatter3d(x=df_copy.iloc[:,0], y=df_copy.iloc[:,1], z=df_copy.iloc[:,2], mode='markers',marker=dict(color=kmeans.labels_, colorscale='rainbow', size = 7, line = dict(width = 0)))\n",
    "        layout = go.Layout(scene = Scene, height = 1000,width = 1000)\n",
    "        data = [trace]\n",
    "        fig = go.Figure(data = data, layout = layout)\n",
    "        fig.update_layout(title=\"KMeans Clusters\", font=dict(size=16))\n",
    "        fig.show()\n",
    "\n",
    "        df_copy.insert(loc=0, column='cluster', value=kmeans.labels_)\n",
    "        print(df_copy.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_kmedoids(df, n_clusters=3, init_method='k-medoids++', n_components=2):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_copy)\n",
    "    X_scale = scaler.transform(df_copy)\n",
    "    df_copy = pd.DataFrame(X_scale, columns=df_copy.columns)\n",
    "    \n",
    "    # Reduce dimensionality with PCA\n",
    "    if len(df_copy.columns) > 3:\n",
    "        # Analyse PCA\n",
    "        if DEBUG:\n",
    "            pca_analysis(df)\n",
    "        df_pca = pca(n_components, df_copy)\n",
    "        if DEBUG:\n",
    "            elbow_method(df_pca)\n",
    "\n",
    "        # Apply K-Medoids\n",
    "        kmedoids = KMedoids(n_clusters=n_clusters, method='pam', init=init_method)\n",
    "        kmedoids.fit(df_pca)\n",
    " \n",
    "        print(\"\\nKMedoids Clusters: \\n\", Counter(kmedoids.labels_))\n",
    "        print(\"KMedoids Centers: \\n\", kmedoids.cluster_centers_)\n",
    "        print(f'KMedoids Inertia: \\n{kmedoids.inertia_}')\n",
    "        print(f'KMedoids Silhouette Score: \\n{silhouette_score(df_pca, kmedoids.labels_)}')\n",
    "\n",
    "        # Plot results\n",
    "        if n_components == 2:\n",
    "            Scene = dict(xaxis = dict(title  = 'PC1'),yaxis = dict(title  = 'PC2'))\n",
    "            trace = go.Scatter(x=df_pca.iloc[:,0], y=df_pca.iloc[:,1], mode='markers',marker=dict(color = kmedoids.labels_, colorscale='rainbow', size = 6, line = dict(width = 0)))\n",
    "        else: \n",
    "            Scene = dict(xaxis = dict(title  = 'PC1'),yaxis = dict(title  = 'PC2'), zaxis= dict(title  = 'PC3'))\n",
    "            trace = go.Scatter3d(x=df_pca.iloc[:,0], y=df_pca.iloc[:,1], z=df_pca.iloc[:,2], mode='markers',marker=dict(color = kmedoids.labels_, colorscale='rainbow', size = 6, line = dict(width = 0)))\n",
    "        layout = go.Layout(scene = Scene, height = 1000,width = 1000)\n",
    "        data = [trace]\n",
    "        fig = go.Figure(data = data, layout = layout)\n",
    "        fig.update_layout(title=\"KMedoids Clusters\",font=dict(size=16))\n",
    "        fig.show()\n",
    "    else:\n",
    "        if DEBUG:\n",
    "            elbow_method(df_copy)\n",
    "\n",
    "        # Apply K-Medoids\n",
    "        kmedoids = KMedoids(n_clusters=n_clusters, method='pam', init=init_method)\n",
    "        kmedoids.fit_predict(df_copy)\n",
    "\n",
    "        print(\"KMedoids Clusters: \\n\", Counter(kmedoids.labels_))\n",
    "        print(\"KMedoids Centers: \\n\", kmedoids.cluster_centers_)\n",
    "        print(f'KMedoids Inertia: {kmedoids.inertia_}')\n",
    "        print(f'KMedoids Silhouette Score: {silhouette_score(df_copy, kmedoids.labels_)}')\n",
    "\n",
    "        # Plot results\n",
    "        if len(df_copy.columns) == 2:\n",
    "            Scene = dict(xaxis = dict(title = df_copy.columns[0]),yaxis = dict(title  = df_copy.columns[1]))\n",
    "            trace = go.Scatter(x=df_copy.iloc[:,0], y=df_copy.iloc[:,1], mode='markers',marker=dict(color=kmedoids.labels_, colorscale='rainbow', size = 7, line = dict(width = 0)))\n",
    "        else: \n",
    "            Scene = dict(xaxis = dict(title = df_copy.columns[0]),yaxis = dict(title = df_copy.columns[1]), zaxis= dict(title = df_copy.columns[2]))\n",
    "            trace = go.Scatter3d(x=df_copy.iloc[:,0], y=df_copy.iloc[:,1], z=df_copy.iloc[:,2], mode='markers',marker=dict(color=kmedoids.labels_, colorscale='rainbow', size = 7, line = dict(width = 0)))\n",
    "        layout = go.Layout(scene = Scene, height = 1000,width = 1000)\n",
    "        data = [trace]\n",
    "        fig = go.Figure(data = data, layout = layout)\n",
    "        fig.update_layout(title=\"KMedoids Clusters\", font=dict(size=16))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_dbscan(df, eps=0.9, min_samples=4, n_components=2):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_copy)\n",
    "    X_scale = scaler.transform(df_copy)\n",
    "    df_copy = pd.DataFrame(X_scale, columns=df_copy.columns)\n",
    "\n",
    "    # Reduce dimensionality with PCA\n",
    "    if len(df_copy.columns) > 3:\n",
    "        # Analyse PCA\n",
    "        if DEBUG:\n",
    "            pca_analysis(df)\n",
    "        df_pca = pca(n_components, df)\n",
    "        if DEBUG:\n",
    "            dbscan_param_tuning_silhouette(df_pca)\n",
    "\n",
    "        # Apply DBSCAN\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(df_pca)\n",
    "        labels = dbscan.labels_\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "        print('Estimated number of clusters: %d' % n_clusters_)\n",
    "        print('Estimated number of noise points: %d' % n_noise_)\n",
    "        print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(df_pca, labels))\n",
    "\n",
    "        # Plot results\n",
    "        labels = dbscan.labels_\n",
    "        if n_components == 2:\n",
    "            Scene = dict(xaxis = dict(title  = 'PC1'),yaxis = dict(title  = 'PC2'))\n",
    "            trace = go.Scatter(x=df_pca.iloc[:,0], y=df_pca.iloc[:,1], mode='markers',marker=dict(color = labels, colorscale='rainbow', size = 6, line = dict(width = 0)))\n",
    "        else: \n",
    "            Scene = dict(xaxis = dict(title  = 'PC1'),yaxis = dict(title  = 'PC2'), zaxis= dict(title  = 'PC3'))\n",
    "            trace = go.Scatter3d(x=df_pca.iloc[:,0], y=df_pca.iloc[:,1], z=df_pca.iloc[:,2], mode='markers',marker=dict(color = labels, colorscale='rainbow', size = 6, line = dict(width = 0)))\n",
    "        layout = go.Layout(scene = Scene, height = 1000,width = 1000)\n",
    "        data = [trace]\n",
    "        fig = go.Figure(data = data, layout = layout)\n",
    "        fig.update_layout(title=\"'DBSCAN Clusters Derived from PCA'\", font=dict(size=12,))\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        if DEBUG:\n",
    "            dbscan_param_tuning_silhouette(df_copy)\n",
    "\n",
    "        # Apply DBSCAN\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(df_copy)\n",
    "        labels = dbscan.labels_\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "        print('Estimated number of clusters: %d' % n_clusters_)\n",
    "        print('Estimated number of noise points: %d' % n_noise_)\n",
    "        print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(df_copy, labels))\n",
    "\n",
    "        # Plot results\n",
    "        labels = dbscan.labels_\n",
    "        if len(df_copy.columns) == 2:\n",
    "            Scene = dict(xaxis = dict(title = df_copy.columns[0]),yaxis = dict(title  = df_copy.columns[1]))\n",
    "            trace = go.Scatter(x=df_copy.iloc[:,0], y=df_copy.iloc[:,1], mode='markers',marker=dict(color = labels, colorscale='rainbow', size = 7, line = dict(width = 0)))\n",
    "        else: \n",
    "            Scene = dict(xaxis = dict(title = df_copy.columns[0]),yaxis = dict(title = df_copy.columns[1]), zaxis= dict(title = df_copy.columns[2]))\n",
    "            trace = go.Scatter3d(x=df_copy.iloc[:,0], y=df_copy.iloc[:,1], z=df_copy.iloc[:,2], mode='markers',marker=dict(color = labels, colorscale='rainbow', size = 7, line = dict(width = 0)))\n",
    "        layout = go.Layout(scene = Scene, height = 1000,width = 1000)\n",
    "        data = [trace]\n",
    "        fig = go.Figure(data = data, layout = layout)\n",
    "        fig.update_layout(title=\"'DBSCAN Clusters'\", font=dict(size=12,))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_kmeans(df[['withdrawal_amount_avg','credit_amount_avg','diff_salary_loan']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_kmedoids(df[['withdrawal_amount_avg','credit_amount_avg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_dbscan(df[['credit','frequency']],0.2, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('3.10.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99f1f04becf66b291a43c00d0d69d8b2cfa065c95007f4165098052401428b70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
